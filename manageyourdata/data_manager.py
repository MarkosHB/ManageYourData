import os
import pandas as pd
from fpdf import FPDF
from langchain.agents import AgentExecutor
from langchain_core.messages import HumanMessage, AIMessage
from manageyourdata import metrics
from manageyourdata import pdf_generator
from manageyourdata.utils import constants
from manageyourdata.models import (
    create_llm_agent, 
    create_dataframe_agent, 
    PROMPT_TEMPLATE,
)


class DataManager:

    # Basic variables.
    data: pd.DataFrame = None
    file_name: str = None
    # Report related variables.
    general_details: dict = {}
    fields_details: list[dict] = []
    # AI agent related variables.
    assistant: AgentExecutor = None
    msgs_history: list[HumanMessage | AIMessage] = []


    def load_data(self, file_path: str) -> pd.DataFrame:
        """Function to read data provided by the user.

        Args:
            file_path (str): Route where the data file is found.

        Raises:
            ValueError: File format not supported.
        """    

        self.file_name = os.path.splitext(os.path.basename(file_path))[0]

        if file_path.endswith(".csv"):
            self.data = pd.read_csv(file_path)
        
        elif file_path.endswith(".xlsx"):
            self.data = pd.read_excel(file_path)

        else:
            raise ValueError("File format not supported.")
        
    
    def report_pdf(self, output_path: str):
        """Function to generate the default PDF report template.

        Args:
            output_path (str): Destination route to save the report.
        """                

        if self.data is None:
            raise ValueError("No data loaded before generating the report.")

        # Store metrics for future analysis.
        self.general_details = metrics.general_details(self.data, self.file_name)
        self.fields_details = metrics.fields_details(self.data, self.file_name)

        # Create doc.
        pdf = FPDF()
        pdf_generator.heading(pdf)
        pdf_generator.general_info(pdf, self.general_details, self.file_name)
        pdf_generator.fields_info(pdf, self.fields_details, self.file_name)
        pdf.output(output_path, 'F')


    def export_data(self, option: str) -> None:
        """Function to export in determined format.

        Args:
            option (str): Desired supported option for file format. 

        Raises:
            ValueError: Export format not supported.
        """        

        if self.data is None:
            raise ValueError("No data loaded before exporting.")

        file_extension = constants.FORMAT[option]
        os.makedirs(f"exports", exist_ok=True)
        export_path = f"exports/{self.file_name}-exported{file_extension}"
        
        if file_extension == ".csv":
            self.data.to_csv(export_path, index=False)

        elif file_extension == ".xlsx":
            self.data.to_excel(export_path, index=False)

        else:
            raise ValueError("Export format not supported.")


    def create_assistant (self, provider: str, model: str, api_key: str | None):
        """Function to create the AI agent to interact with the data.

        Args:
            provider (str): LLM provider to be used.
            model (str): Model name to be used.
            api_key (str | None): API key for providers that require authentication.

        Raises:
            ValueError: LLM could not be initialized.
        """
        
        try:
            # Create llm instance.
            llm = create_llm_agent(provider, model, api_key)
            # Create agent instance.
            self.agent = create_dataframe_agent(llm, self.data)           

        except Exception:
            raise ValueError(f"Error initializing the AI agent.")
        
        
    def chat_with_assistant(self, prompt: str) -> str:
        """Function to interact with the data using AI.

        Args:
            prompt (str): Question or command to be processed by the agent.

        Returns:
            str: The response generated by the agent.
        """

        if self.agent is None:
            raise ValueError("No AI agent has been created before the interaction.")
        
        # Append user message to the history.
        human_msg = HumanMessage(content=prompt)
        self.msgs_history.append(human_msg)

        # Create chain and get response.
        chain = PROMPT_TEMPLATE | self.agent
        response = chain.invoke(
            {                
                "general_details":self.general_details,
                "fields_details": self.fields_details,
                "msgs": self.msgs_history
            }
        )
        
        # Append AI message to the history.
        ai_msg = AIMessage(content=response["output"])
        self.msgs_history.append(ai_msg)
        
        return response["output"]
    

    def delete_historic(self):
        """Function to delete the message history."""
        self.msgs_history = []


    def get_historic(self) -> list[HumanMessage | AIMessage]:
        """Function to get the message history.

        Returns:
            list[HumanMessage | AIMessage]: The message history.
        """
        return self.msgs_history
    